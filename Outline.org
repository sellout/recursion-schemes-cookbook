#+title: Modular Induction & Coinduction

* Part the First

** Reintroducing Recursion

Here is just everything about recursion as you usually know it

This chapter is probably mostly a review for you. But it serves to get us all on
the same page with concepts and terminology. Unfortunately, this book also
involves "unlearning" much of this. Perhaps some day there we can write a book
that introduces the modularity described in this book directly, rather than
having to de-program everyone.

So, what /is/ recursion? 

As an industry, we often contrast recursion with iteration, but recursion subsumes
iteration. Syntactically, many languages have a special syntax for iteration
constructs, but there is nothing that prevents us from implementing that syntax
with recursion.

So, what are some recursive (or iterative) things  you can think of?

- applying some function to every element in a list
- refining a result repeatedly, until it's stable enough

*** Exercises

- mostly simple, at the end of each section
- last section introduces the "project"

** Generalized traversals

Uniplate style, introduces traversals without yet getting into algebras and pattern functors.

** Guaranteed structure

Uniplate lets functions dig arbitrarily deep into a tree, and they pair each
element with a list of child results (~para~?), so it's quite possible that the
list of results doesn't correspond to the children of the current node. How do
we fix this?

This section probably also /separates/ recursion from the business logic.

* Practical application

I'm not quite sure where to split sections between "part the first" and
"practical application", but the conceptual distinction we want to make is that
we're basically done justifying recursion schemes, and are now on to using them
well. So the balance of examples and exercises moves from things we don't
actually recommend (direct recursion, uniplate) to things we do.

Along with that means some content about how to transition existing code bases
(without recursion schemes) to ones that use recursion schemes.

** extending existing code

(this is the use case for [[https://hackage.haskell.org/package/yaya-0.3.2.0/docs/Yaya-Retrofit.html][~Yaya.Retrofit~]])

- define a pattern functor parallel to your existing type
- define ~Steppable~ instances -- an isomorphism between the existing type and
  the pattern functor
- define (~Co~)~Recursive~ instances using the default direct recursion
  implementations (~algebra . fmap (cata algebra) . project~)

Yaya's ~extractPatternFunctor~ can do this automatically in some cases.

now you can define new operations using algebras and folds, and eventually you
can replace

#+begin_src haskell
data PatternStructure = ...

data OriginalStructure = ...

instance Projectable OriginalStructure PatternStructure where ...
instance Steppable OriginalStructure PatternStructure where ...
instance Recursive OriginalStructure PatternStructure where ...
instance Corecursive OriginalStructure PatternStructure where ...
#+end_src

with

#+begin_src haskell
data PatternStructure = ...

type OriginalStructure = Mu PatternStructure
#+end_src

An alternative in some cases is to start by replacing the original type with ~Mu
PatternStructure~, but defining the alias like ~type OriginalStructure =
PatternStructure (Mu PatternStructure)~. This gives you recursion schemes more
completely up-front, but avoids having to change code that only does shallow
pattern matching.

** total traversals

This section maybe eliminates recursion altogether

** little pieces

- introduce modularity via ~Cofree~

- introduce fusion via ~zygo~

** beautiful folds

- getting away from writing algebras explicitly as algebras, this is where the "proto-algebras" section comes in
- write obvious functions, then convert them into algebras when applying the fold
- introduce the general vocabulary of "algebra transformers" (e.g., ~annotateAlgebra~, ~zipAlgebras~)

Maybe before this chapter, but we need to address the naming problem with
pattern functors and algebras. We're used to naming folds, like ~filter~, but
for maximum reusability and efficiency, we want to expose the underlying
proto-algebra that embodies a single step of ~filter~. That, in itself, isn't
~filter~, but what is it? Sometimes these things have reasonable names, but even
when they do, their single-step name isn't necessarily related to their purpose
in a fold. And often a proto-algebra can be used multiple ways in a fold, with
distinct purposes -- how do we try to name things well so that the name at least
hints at its purpose (comments can always be used to add detail to those hints).

One of the things we /shouldn't/ do is have ~Foo ~ Fix FooF~. For
pattern-functors, I have two naming styles, one is to name the functor as you
would have previously named the fixed point, like ~data Expr a~ and then the
tree is ~Fix Expr~. This makes especially good sense when you do graph-like
stuff or assignment-like stuff, where you have like ~[Expr Var]~, where each
expression is atomic, referring only to variables previously assigned, never
having nested expressions. The other pattern-functor naming style is to name the
functor very explicitly, which is useful when it's particularly generic, e.g.,

#+begin_src haskell
-- read as @a `AndMaybe` b@
data AndMaybe a b
  = Only a
  | Indeed a b

type NonEmpty a = Mu (AndMaybe a)
#+end_src

For (proto-)algebras, I lean toward that second style as much as possible, this
is because I find algebras are much more flexible. They may serve many different
purposes in a fold, and so leaving the name more ambiguous avoids pinning down
what they're "supposed to" be used for.

*** Examples

Breaking down some of the more complicated examples using zygomorphism

** leafward data passing

This is the reason to not introduce unfolding earlier -- people often think of
folds as passing data rootward, and unfolds as passing data leafward, but you
can do either with either, and the /important/ distinction is that folds are
finite, so even if you want to pass data leafward, if you want to keep things
finite, you do it with a fold.

But in this case, the carrier of the algebra is a function. E.g., ~f (a -> b) ->
(a -> b)~, where ~b~ is the usual rootward data passing and ~a~ is the leafward
data passing.

* Advanced Topics

** streaming

Probably don't talk about unfolding /at all/ before this? I think it's too easy
for people to use unfolds when they should stick with folds.

- [[http://www.cs.ox.ac.uk/jeremy.gibbons/publications/metamorphisms-scp.pdf][metamorphisms]]

** graphs

- [[https://github.com/snowleopard/alga-paper][algebraic graphs]]

*** acyclic vs cyclic

- [[https://ku-fpg.github.io/files/Gill-09-TypeSafeReification.pdf][Type-Safe Observable Sharing]]

*** (multi-)rooted

** connection to category theory

Ziyang's blog post fits here.
